{"cells":[{"cell_type":"markdown","metadata":{"id":"epdXLGCD6oDb"},"source":["# Implmentation of LSTM and GRU\n","\n","The maximum accuracy achived on MNIST for both LSTM and GRU is 97%. \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-CClZsM6oDf"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)"]},{"cell_type":"markdown","metadata":{"id":"OGdph6Ez6oDl"},"source":["### Learning curve for GRU and LSTM"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydeS6SHN6oDm"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torchvision.transforms as transforms\n","import torchvision.datasets as dsets\n","from torch.autograd import Variable\n","from torch.nn import Parameter\n","from torch import Tensor\n","import torch.nn.functional as F\n","import glob,os\n","import math\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n","                              TensorDataset)\n","\n","cuda = True if torch.cuda.is_available() else False\n","    \n","Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor    \n","\n","torch.manual_seed(125)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(125)\n"]},{"cell_type":"code","source":["from google.colab import drive\n","import pandas as pd\n","drive.mount('/content/gdrive')"],"metadata":{"id":"B_bFV8JG61G1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["base_path = \"/content/gdrive/MyDrive/Infinite hand/alphabet\""],"metadata":{"id":"gd4U_b1D7hzJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QuNWs9kD6oDn"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b0e71T7G6oDo"},"outputs":[],"source":["#read train dataset\n","train_dir = base_path\n","train_names = glob.glob(os.path.join(train_dir, '*') )\n","train_numpy = []\n","train_name = []\n","for image_path in train_names:\n","    #print(image_path)\n","    alphabet = image_path[-7]\n","    alphabet = ord(alphabet)-65\n","    alp_arr = [alphabet] * 95\n","    im = np.load(image_path)\n","    train_numpy.append(im[5:])\n","    train_name.append(alp_arr)\n","    print(image_path[-7],alphabet,len(train_numpy))\n","train_numpy = np.array(train_numpy).reshape(([-1,4,400])).astype('float')\n","train_numpy = np.transpose(train_numpy, (0, 2, 1))\n","train_name = np.array(train_name).reshape((-1))\n","np.save('train',train_numpy)\n","np.save('train_alphabet',train_name)\n","print(train_numpy.shape)\n","print(train_name.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gjllBZs56oDp"},"outputs":[],"source":["for i in range(len(train_numpy)):\n","    for k in range(3):\n","        max_num = np.max(train_numpy[i,:,k])\n","        min_num = np.min(train_numpy[i,:,k])\n","        if((max_num - min_num)!= 0):\n","            train_numpy[i,:,k] = (train_numpy[i,:,k]-min_num)/(max_num - min_num)\n","        else:\n","            train_numpy[i,:,k] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0f0ngWl36oDq"},"outputs":[],"source":["class CustomTensorDataset(TensorDataset):\n","    \"\"\"TensorDataset with support of transforms.\n","    \"\"\"\n","    def __init__(self, tensors,alphabet):\n","        self.tensors = tensors\n","        self.alphabet = alphabet\n","        \n","    def __getitem__(self, index):\n","        x = self.tensors[index]\n","        alph = self.alphabet[index]\n","        return x,alph.float() \n","\n","    def __len__(self):\n","        return len(self.tensors)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MMqCDWDJ6oDr"},"outputs":[],"source":["batch_size = 64\n","data = torch.from_numpy(train_numpy)\n","name = torch.from_numpy(train_name)\n","full_dataset = CustomTensorDataset(data,name)\n","train_size = int(0.8 * len(full_dataset))\n","test_size = len(full_dataset) - train_size\n","train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n","train_sampler = RandomSampler(train_dataset)\n","train_dataloader = DataLoader(train_dataset, sampler=train_sampler, batch_size=batch_size)\n","test_sampler = RandomSampler(test_dataset)\n","test_dataloader = DataLoader(test_dataset, sampler=test_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r_2dH6LY6oDs"},"outputs":[],"source":["train_dataset[3]"]},{"cell_type":"markdown","metadata":{"id":"4REhQifv6oDt"},"source":["## GRU cell implmentation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7_cOubpK6oDt"},"outputs":[],"source":["class GRUCell(nn.Module):\n","\n","    \"\"\"\n","    An implementation of GRUCell.\n","\n","    \"\"\"\n","\n","    def __init__(self, input_size, hidden_size, bias=True):\n","        super(GRUCell, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.bias = bias\n","        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n","        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n","        self.reset_parameters()\n","\n","\n","\n","    def reset_parameters(self):\n","        std = 1.0 / math.sqrt(self.hidden_size)\n","        for w in self.parameters():\n","            w.data.uniform_(-std, std)\n","    \n","    def forward(self, x, hidden):\n","        \n","        x = x.view(-1, x.size(1))\n","        \n","        gate_x = self.x2h(x) \n","        gate_h = self.h2h(hidden)\n","        \n","        gate_x = gate_x.squeeze()\n","        gate_h = gate_h.squeeze()\n","        if(len(gate_x.size())<=1):\n","            gate_x = gate_x.unsqueeze(0)\n","            gate_h = gate_h.unsqueeze(0)             \n","        i_r, i_i, i_n = gate_x.chunk(3, 1)\n","        h_r, h_i, h_n = gate_h.chunk(3, 1)\n","        \n","        \n","        resetgate = F.sigmoid(i_r + h_r)\n","        inputgate = F.sigmoid(i_i + h_i)\n","        newgate = F.tanh(i_n + (resetgate * h_n))\n","        \n","        hy = newgate + inputgate * (hidden - newgate)\n","        \n","        \n","        return hy\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"J3cv_7Im6oDv"},"outputs":[],"source":["class GRUModel(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n","        super(GRUModel, self).__init__()\n","        # Hidden dimensions\n","        self.hidden_dim = hidden_dim\n","         \n","        # Number of hidden layers\n","        self.layer_dim = layer_dim\n","         \n","       \n","        self.gru_cell = GRUCell(input_dim, hidden_dim, layer_dim)\n","        \n","        \n","        self.fc = nn.Linear(hidden_dim, output_dim)\n","     \n","    \n","    \n","    def forward(self, x):\n","        \n","        # Initialize hidden state with zeros\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","        #print(x.shape,\"x.shape\")100, 28, 28\n","        if torch.cuda.is_available():\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n","        else:\n","            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n","         \n","       \n","        outs = []\n","        \n","        hn = h0[0,:,:]\n","        \n","        for seq in range(x.size(1)):\n","            hn = self.gru_cell(x[:,seq,:], hn) \n","            outs.append(hn)\n","            \n","\n","        out = outs[-1].squeeze()\n","        \n","        out = self.fc(out) \n","        # out.size() --> 100, 10\n","        return out\n"," "]},{"cell_type":"markdown","metadata":{"id":"Kfz-9wqB6oDv"},"source":["## LSTM cell implementation"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PC5qHtnk6oDw"},"outputs":[],"source":["'''\n","STEP 4: INSTANTIATE MODEL CLASS\n","'''\n","input_dim = 4\n","hidden_dim = 128\n","layer_dim = 1  # ONLY CHANGE IS HERE FROM ONE LAYER TO TWO LAYER\n","output_dim = 26\n"," \n","# model = LSTMModel(input_dim, hidden_dim, layer_dim, output_dim)\n","model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n","\n","#######################\n","#  USE GPU FOR MODEL  #\n","#######################\n"," \n","if torch.cuda.is_available():\n","    model.cuda()\n","     \n","'''\n","STEP 5: INSTANTIATE LOSS CLASS\n","'''\n","criterion = nn.CrossEntropyLoss()\n"," \n","'''\n","STEP 6: INSTANTIATE OPTIMIZER CLASS\n","'''\n","learning_rate = 0.1\n"," \n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U9GxNug_6oDw"},"outputs":[],"source":["from torchvision import models\n","from torchsummary import summary\n","summary(model, (400, 4))"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"8Xy_KmuH6oDx"},"outputs":[],"source":["'''\n","STEP 7: TRAIN THE MODEL\n","'''\n"," \n","# Number of steps to unroll\n","seq_dim = 400\n","batch_size = 32\n","num_epochs = 6000\n","loss_list = []\n","iter = 0\n","for epoch in range(num_epochs):\n","    for i,(images, labels) in enumerate(train_dataloader):\n","        # Load images as Variable\n","        #######################\n","        #  USE GPU FOR MODEL  #\n","        #######################\n","          \n","        if torch.cuda.is_available():\n","            images = Variable(images.view(-1, seq_dim, input_dim).cuda().float())\n","            #print(images.size())\n","            #print(labels)\n","            #print(images)\n","            #print(type(images))\n","            #print(type(labels))\n","            labels = Variable(labels.cuda())\n","        else:\n","            images = Variable(images.view(-1, seq_dim, input_dim).float() )\n","            labels = Variable(labels)\n","        #print(labels)\n","        # Clear gradients w.r.t. parameters\n","        optimizer.zero_grad()\n","         \n","        # Forward pass to get output/logits\n","        # outputs.size() --> 100, 10\n","        outputs = model(images)\n","        #print(outputs.dtype)\n","        #print(labels.to(torch.int64).dtype)\n","        # Calculate Loss: softmax --> cross entropy loss\n","        loss = criterion(outputs, labels.to(torch.int64))\n","\n","        if torch.cuda.is_available():\n","            loss.cuda()\n","\n","        # Getting gradients w.r.t. parameters\n","        loss.backward()\n","\n","        # Updating parameters\n","        optimizer.step()\n","        \n","        loss_list.append(loss.item())\n","        iter += 1\n","         \n","        if iter % 5 == 0:\n","            # Calculate Accuracy         \n","            correct = 0\n","            total = 0\n","            # Iterate through test dataset\n","            for (images, labels) in test_dataloader:\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    images = Variable(images.view(-1, seq_dim, input_dim).cuda().float())\n","                else:\n","                    images = Variable(images.view(-1 , seq_dim, input_dim).float())\n","                \n","                # Forward pass only to get logits/output\n","                outputs = model(images)\n","                \n","                # Get predictions from the maximum value\n","                _, predicted = torch.max(outputs.data, 1)\n","                 \n","                # Total number of labels\n","                total += labels.size(0)\n","                 \n","                # Total correct predictions\n","                #######################\n","                #  USE GPU FOR MODEL  #\n","                #######################\n","                if torch.cuda.is_available():\n","                    correct += (predicted.cpu() == labels.cpu()).sum()\n","                else:\n","                    correct += (predicted == labels).sum()\n","             \n","            accuracy = 100 * correct / total\n","             \n","            # Print Loss\n","            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cZUZImzs6oDy"},"outputs":[],"source":["torch.save(model, 'all_final.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LEdLzgc26oDz"},"outputs":[],"source":["torch.save(model.state_dict(), 'all_weight.pt')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FgnD7VMY6oDz"},"outputs":[],"source":["#model = torch.load('all.pt').cuda()\n","model.load_state_dict(torch.load(\"all_weight.pt\")) "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zrDkHGlK6oDz"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BRbEiijO6oD0"},"outputs":[],"source":["import time\n","\n","start = time.time()\n","outputs = model(images)\n","end = time.time()\n","print(end - start)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"abowOaRZ6oD0"},"outputs":[],"source":["import serial\n","import mouse\n","import time\n","model.load_state_dict(torch.load(\"all_weight.pt\")) \n","ser = serial.Serial(\"COM11\", 9600)\n","last_band = 0\n","while True:\n","    read_bluetooth=ser.readline()\n","    #print(read_bluetooth[0],read_bluetooth[1])\n","    #print(read_bluetooth.shape())\n","    try:\n","        read_value_x = int(read_bluetooth[0])-127\n","        read_value_y = int(read_bluetooth[1])-127\n","        read_value_z = int(read_bluetooth[2])-127\n","    except:\n","        pass\n","    bend = 0\n","    try:\n","        pressure1 = read_bluetooth[3] #食指\n","        pressure2 = read_bluetooth[4]\n","        bend = read_bluetooth[5]\n","    except:\n","         pass\n","    if (abs(read_value_x)<3):\n","         read_value_x = 0\n","    if (abs(read_value_y)<3):\n","         read_value_y = 0\n","    ratio = 1\n","    if (bend == 1):\n","        if(last_band==0):\n","            for k in range(50):\n","                read_bluetooth=ser.readline()\n","        sec_x = []\n","        sec_y = []\n","        sec_z = []\n","        for i in range(300):\n","            read_bluetooth=ser.readline()\n","            try:\n","                read_value_x = int(read_bluetooth[0])-127\n","                read_value_y = int(read_bluetooth[1])-127\n","                read_value_z = int(read_bluetooth[2])-127\n","            except:\n","                pass\n","            sec_x.append(read_value_x)\n","            sec_y.append(read_value_y)\n","            sec_z.append(read_value_z)\n","        sec_all = [sec_x,sec_y,sec_z]\n","        for ax in range(3):\n","            for j in range(300):\n","                temp = j\n","                while (sec_all[ax][j]<-80):\n","                    temp = j-1\n","                    sec_all[ax][j] = sec_all[ax][temp]\n","\n","        train_numpy = np.array(sec_all).reshape(([-1,3,300])).astype('float')\n","        train_numpy = np.transpose(train_numpy, (0, 2, 1))\n","        for i in range(len(train_numpy)):\n","            for k in range(3):\n","                max_num = np.max(train_numpy[i,:,k])\n","                min_num = np.min(train_numpy[i,:,k])\n","                if((max_num - min_num)!= 0):\n","                    train_numpy[i,:,k] = (train_numpy[i,:,k]-min_num)/(max_num - min_num)\n","                else:\n","                    train_numpy[i,:,k] = 0\n","        data = torch.from_numpy(train_numpy).cuda().float()\n","        with torch.no_grad():\n","            outputs = model(data)\n","        print('get',chr(np.argmax(outputs.cpu().detach().numpy()) + 97 ))\n","        last_band = 1\n","    elif (pressure1>150 and pressure2>150):\n","        last_band = 0\n","        mouse.right_click()\n","        #print('right')\n","        for i in range(5):\n","            read_bluetooth=ser.readline()\n","    else:\n","        last_band = 0\n","        if (pressure1>30 and pressure2>30 ):\n","            if (read_value_y>5):\n","                mouse.wheel(1)\n","               \n","            else:\n","                mouse.wheel(-1)\n","               \n","               \n","        elif (pressure1>30):\n","            mouse.move(-read_value_x*ratio, read_value_y*ratio, absolute=False) #用1.5秒移動到x=100，y=100的位置\n","        if (pressure1>=150):\n","            mouse.click()\n","            for i in range(30):\n","                read_bluetooth=ser.readline()\n","           #print('left')\n","       #else:\n","           #mouse.release()\n","           #print('release')\n","         #mouse.click('left')\n","         #for i in range(30):\n","         #     read_bluetooth=ser.readline()\n","    print(read_value_x,read_value_y,read_value_z,pressure1,pressure2,bend)\n","    #print(read_value)\n","    #print(ser.readline().decode(\"utf-8\"))\n","    #print(read_bluetooth.decode(encoding='UTF-8',errors='strict'),type(read_bluetooth))"]},{"cell_type":"code","source":["k = 66\n","a = np.load(base_path+'/'+chr(k)+chr(k)+'.npy')\n","print(a.shape)\n","plt.plot(a[15][2])"],"metadata":{"id":"_cMTfb517wnP"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TkteFr_X6oD1"},"outputs":[],"source":["for k in range (65,92):\n","    #alphabet = ord(alphabet)-97\n","    a = np.load(base_path+'/'+chr(k)+chr(k)+'.npy')\n","    for ax in range(3):\n","        for i in range(5,100):\n","            for j in range(400):\n","                temp = j\n","                while (a[i][ax][j]<-60):\n","                    temp = j-1\n","                    a[i][ax][j] = a[i][ax][temp]\n","    for ax in range(4):\n","        for i in range(5,100):\n","            min = np.mean(a[i][ax])\n","            max = np.max(a[i][ax])\n","            a[i][ax] = (a[i][ax]-min )/(max-min)\n","    np.save(base_path+'/'+chr(k)+'_r',a)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ulLGnK5A6oD1"},"outputs":[],"source":["a.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6MABaSPS6oD2"},"outputs":[],"source":["a[0][0]\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","for ax in range(3):\n","    for i in range(5,100):\n","        for j in range(300):\n","            temp = j\n","            while (a[i][ax][j]<-80):\n","                temp = j-1\n","                a[i][ax][j] = a[i][ax][temp]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wzbFQYjZ6oD2"},"outputs":[],"source":["a = np.load('alphabet/c_r.npy')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EiVlyzGE6oD3"},"outputs":[],"source":["a.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0cR8q6m6oD3"},"outputs":[],"source":["thres = 8\n","thre = []\n","for k in range(100):\n","    for ax in range(300):\n","        if ((a[k][0][ax]**2+a[k][1][ax]**2+a[k][2][ax]**2)**0.5>thres):\n","            print(ax)\n","            thre.append(ax)\n","            break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1WEW8EsV6oD4"},"outputs":[],"source":["k[1]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r70Y0NIk6oD4"},"outputs":[],"source":["for k in range(len(thre)):\n","    for i in range(15,45):\n","        plt.plot(a[i][0][thre[i]:thre[i]+195])\n","plt.show()\n","for k in range(len(thre)):\n","    for i in range(15,45):\n","        plt.plot(a[i][1][thre[i]:thre[i]+195])\n","plt.show()\n","for k in range(len(thre)):\n","    for i in range(15,45):\n","        plt.plot(a[i][2][thre[i]:thre[i]+195])\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nz-IKHZz6oD5"},"outputs":[],"source":[""]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"lstm_gru-all.ipynb","private_outputs":true,"provenance":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}